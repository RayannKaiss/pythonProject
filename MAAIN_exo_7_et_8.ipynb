{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf5770d",
   "metadata": {},
   "source": [
    "### Dico to liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7430e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionnaire mot fréquence : dico\n",
    "dico = {'il':5 , 'est':2 , 'voiture':3, 'un': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b14669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplification(dico): \n",
    "    vocab=[]\n",
    "    freq=[]\n",
    "    for key, value in dico.items():\n",
    "        vocab+=[key]\n",
    "        freq+=[value]\n",
    "    return vocab, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9497389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['il', 'est', 'voiture', 'un']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab, freq=simplification(dico)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6322d6f",
   "metadata": {},
   "source": [
    "### Synchronisation indice - id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer liste pour chopper le texte (l'indice de cette liste synchronise avec l'id des pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0007d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(\"qlqpage.xml\")\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9365845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n"
     ]
    }
   ],
   "source": [
    "for page in root:\n",
    "    for text in page.findall('text'):\n",
    "        contenu = text.text\n",
    "        print(\"lol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6474ddaa",
   "metadata": {},
   "source": [
    "### Liens internes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db01fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def liens_internes(text): \n",
    "    liens=[]\n",
    "    for i in range(len(text)-1):\n",
    "        if text[i]=='[' and text[i+1]=='[':\n",
    "            debut=i+2\n",
    "        if text[i]==']' and text[i+1]==']':\n",
    "            fin = i-1\n",
    "            ref = text[debut:fin+1]\n",
    "            if not ref in liens:\n",
    "                liens+=[ref]\n",
    "            \n",
    "    return liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6606fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Organigramme de programmation',\n",
       " \"algorithme d'Euclide\",\n",
       " \"algorithme d'Euclide]].\",\n",
       " 'algorithme',\n",
       " 'problème algorithmique',\n",
       " 'mathématicien',\n",
       " 'Al-Khwârizmî',\n",
       " 'Philippe Flajolet',\n",
       " 'Moyen Âge',\n",
       " 'Abrégé du calcul par la restauration et la comparaison|le premier ouvrage systématique',\n",
       " 'équation linéaire|équations linéaires',\n",
       " 'équation du second degré|quadratiques',\n",
       " 'Josef Hoëné-Wronski|Wronski',\n",
       " 'Josef Hoëné-Wronski|Hoéné de Wronski',\n",
       " 'Université du Québec à Montréal|UQAM',\n",
       " \"File:Cuneiform tablet- fragment of a mathematical problem text MET ME86 11 404.jpg|thumb|Fragment d'une tablette cunéiforme avec un problème algorithmique. MET ME86 11 404\",\n",
       " 'Babylone|Babyloniens',\n",
       " 'Calcul (mathématiques)|calcul',\n",
       " 'Équation|équations',\n",
       " 'Donald Knuth',\n",
       " 'Communications of the ACM',\n",
       " 'Addison-Wesley',\n",
       " 'Librairie Eyrolles',\n",
       " \"algorithme d'Euclide|Éléments d'Euclide\",\n",
       " 'Plus grand commun diviseur|PGCD',\n",
       " 'itération',\n",
       " \"correction d'un algorithme|correction\",\n",
       " 'Archimède',\n",
       " 'Pi|π',\n",
       " 'Encyclopædia universalis',\n",
       " 'Persans|perse',\n",
       " 'Abrégé du calcul par la restauration et la comparaison',\n",
       " 'équation du second degré|équations du second degré',\n",
       " 'Mathématiques babyloniennes|Babyloniens',\n",
       " 'Al-Andalus|andalou',\n",
       " 'Averroès',\n",
       " '1126',\n",
       " '1198',\n",
       " 'raisonnement',\n",
       " 'Adelard de Bath',\n",
       " 'latin',\n",
       " '1554',\n",
       " 'René Descartes',\n",
       " 'Discours de la méthode',\n",
       " '1637',\n",
       " 'Recherche dichotomique|dichotomie',\n",
       " 'Programme informatique|programme',\n",
       " '1677',\n",
       " 'Informatique|sciences informatique',\n",
       " 'Ada Lovelace',\n",
       " 'Lord Byron',\n",
       " 'Charles Babbage',\n",
       " 'Nombre de Bernoulli|nombres de Bernoulli',\n",
       " 'Stephen Wolfram',\n",
       " 'dixième problème de Hilbert',\n",
       " 'Problèmes de Hilbert|problèmes',\n",
       " 'David Hilbert',\n",
       " 'machines de Turing',\n",
       " 'Algorithme récursif|algorithmique récursive',\n",
       " 'algorithme parallèle|algorithmique parallèle',\n",
       " 'informatique quantique',\n",
       " 'The Art of Computer Programming',\n",
       " 'langage de programmation',\n",
       " 'codage (programmation)|codage',\n",
       " 'cryptographie',\n",
       " 'code source',\n",
       " 'Niklaus Wirth|N. Wirth',\n",
       " 'structure de contrôle|structures de contrôle',\n",
       " 'Structure de données|structures de données',\n",
       " 'Lisp',\n",
       " 'Prolog',\n",
       " 'algorithme récursif|récursivité',\n",
       " \"Terminaison d'un algorithme|terminaison\",\n",
       " 'notation de Landau|notions de domination',\n",
       " 'fonction mathématique',\n",
       " 'bit',\n",
       " 'Théorie de la complexité (informatique théorique)|complexité algorithmique',\n",
       " 'algorithme de tri',\n",
       " \"complexité en temps|temps d'exécution\",\n",
       " 'complexité en espace|espace mémoire',\n",
       " 'analyse combinatoire|combinatoire',\n",
       " 'Développement asymptotique|évaluation asymptotique',\n",
       " 'série génératrice|séries génératrices',\n",
       " 'analyse complexe',\n",
       " 'combinatoire analytique',\n",
       " 'théorie de la complexité des algorithmes',\n",
       " 'tri rapide',\n",
       " 'Biais (statistique)|biais',\n",
       " 'intelligence artificielle',\n",
       " 'machine learning',\n",
       " 'diagnostic médical|médical',\n",
       " 'aide à la décision',\n",
       " 'réseaux sociaux',\n",
       " 'parcoursup',\n",
       " 'Télécom ParisTech',\n",
       " 'Mémoire virtuelle#Principe de localité|localité',\n",
       " 'mémoire virtuelle',\n",
       " 'mémoire vive',\n",
       " 'tri par tas',\n",
       " 'Mémoire virtuelle#Swapping|swapping',\n",
       " 'analyse amortie|amortie',\n",
       " \"Analyse lisse d'algorithme\",\n",
       " 'algorithme du simplexe',\n",
       " 'algorithme glouton',\n",
       " 'Diviser pour régner (informatique)|diviser pour régner',\n",
       " 'recherche exhaustive',\n",
       " 'programmation dynamique',\n",
       " 'algorithme de Las Vegas',\n",
       " 'algorithme de Monte-Carlo',\n",
       " 'heuristique (mathématiques)|heuristique',\n",
       " 'Échecs|jeu d’échecs',\n",
       " 'jeu de go',\n",
       " 'Logiciel antivirus|logiciels antivirus',\n",
       " 'virus informatique',\n",
       " 'problème SAT',\n",
       " 'problème NP-complet',\n",
       " \"Problème SAT#Algorithmes de SAT|façon pratique et efficace par la mise au point d'heuristiques\",\n",
       " 'Moshe Vardi',\n",
       " 'liste des algorithmes',\n",
       " 'Structure de données',\n",
       " 'Recherche dichotomique',\n",
       " 'problème du voyageur de commerce',\n",
       " 'problème du sac à dos',\n",
       " 'algorithme récursif',\n",
       " 'tours de Hanoï',\n",
       " 'huit dames',\n",
       " 'suite de Conway',\n",
       " 'fractale',\n",
       " 'Tapis de Sierpiński',\n",
       " 'Courbe du dragon',\n",
       " 'Flocon de Koch',\n",
       " 'factorielle',\n",
       " \"Fonction d'Ackermann\",\n",
       " 'suite de Fibonacci',\n",
       " \"fraction continue d'un nombre quadratique\",\n",
       " 'racine carrée',\n",
       " 'méthode de Newton',\n",
       " \"unification|algorithme d'unification\",\n",
       " 'bases de Gröbner|base de Gröbner',\n",
       " 'calcul symbolique',\n",
       " 'Théorie des graphes#Aspect algorithmique|théorie des graphes',\n",
       " 'test de primalité',\n",
       " 'cryptologie',\n",
       " 'compression de données',\n",
       " 'informatique musicale',\n",
       " 'algorithme génétique',\n",
       " 'informatique décisionnelle',\n",
       " 'Compilateur',\n",
       " 'Interprète (informatique)',\n",
       " 'allocation de mémoire',\n",
       " 'ramasse-miettes (informatique)|ramasse-miettes',\n",
       " 'Donald Knuth|Donald E. Knuth',\n",
       " 'Interstices',\n",
       " 'Algorithme récursif',\n",
       " 'Algorithme réparti',\n",
       " 'Algorithme émergent',\n",
       " 'Algorithme adaptatif',\n",
       " \"Algorithme d'approximation\",\n",
       " 'Art algorithmique',\n",
       " \"Liste d'algorithmes\",\n",
       " 'Métaheuristique',\n",
       " 'Recherche opérationnelle',\n",
       " 'Paradigme (programmation)',\n",
       " 'Catégorie:Algorithmique|*',\n",
       " \"Catégorie:Nom dérivé d'un anthroponyme\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liens_internes(root[1].findall('text')[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f93885",
   "metadata": {},
   "source": [
    "### Construction dictionnaire Mot-page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a2d2e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Unidecode\n",
      "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
      "Installing collected packages: Unidecode\n",
      "Successfully installed Unidecode-1.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7187d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker mot-pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73b7aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet=\"0123456789abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28087545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation(vocab): # initialise le dictionnaire voulu avec une liste vide pour la value et l'indice des mot pour la clé\n",
    "    dico={}\n",
    "    for i in range(len(vocab)):\n",
    "        dico[str(i)]=[]\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d119f43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [], '1': [], '2': [], '3': []}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_mot_page = initialisation(vocab)\n",
    "dico_mot_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdc8737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mot_page(text, vocab): # retourne la liste de mot (en indice) dans un texte (sous condition d'être dans le vocab)\n",
    "    mot_=[]\n",
    "    stop=False\n",
    "    for i in range(len(text)):\n",
    "        if ((unidecode.unidecode(text[i].lower()) in alphabet) and stop==False):\n",
    "            debut = i\n",
    "            stop=True\n",
    "        if (not (unidecode.unidecode(text[i].lower()) in alphabet) and stop==True):\n",
    "            fin = i-1\n",
    "            stop=False\n",
    "            mot = unidecode.unidecode(text[debut:fin+1].lower())\n",
    "            for i in range(len(vocab)):\n",
    "                if vocab[i]==mot:\n",
    "                    if not i in mot_:\n",
    "                        mot_+=[i]\n",
    "                    break\n",
    "    return mot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "624e1769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_mot_page1 = mot_page(root[1].findall('text')[0].text, vocab)\n",
    "liste_mot_page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9742f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplissage (dico_mot_page, liste_mot, id_page): # retourne une complétion de dico_mot_page\n",
    "    for id_mot in liste_mot:\n",
    "        dico_mot_page[str(id_mot)]+=[id_page]\n",
    "    return dico_mot_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "808ffce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [0, 1, 2, 3, 4], '1': [0, 1, 2, 3, 4], '2': [], '3': [0, 1, 2, 3, 4]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(root)):\n",
    "    liste_mot_page_i = mot_page(root[i].findall('text')[0].text, vocab)\n",
    "    dico_mot_page = remplissage(dico_mot_page, liste_mot_page_i, i)\n",
    "dico_mot_page   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c340b",
   "metadata": {},
   "source": [
    "### Calcule matrice des coeff TF normalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd6204ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e4599d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(m,d,vocab): #m et d est un indice\n",
    "    mot = vocab[m]\n",
    "    page=root[d]\n",
    "    for text in page.findall('text'): # une seul itération\n",
    "        contenu = text.text\n",
    "        nb = contenu.count(mot)\n",
    "    if(nb==0):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1+math.log10(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ee3596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nd(d, vocab):\n",
    "    nd=0\n",
    "    for i in range(len(vocab)):\n",
    "        nd += TF(i, d, vocab)\n",
    "    return math.sqrt(nd**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f5f230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "longueur_mot = len(vocab)\n",
    "longueur_page = len(root)\n",
    "tab_TF_normalise = np.zeros(longueur_mot*longueur_page)\n",
    "tab_TF_normalise = tab_TF_normalise.reshape((longueur_mot,longueur_page))\n",
    "for j in range(longueur_page):\n",
    "    nd = Nd(j, vocab)\n",
    "    for i in range(longueur_mot):\n",
    "        tab_TF_normalise[i][j]=TF(i,j,vocab)/nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2938a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38641542 0.32733512 0.3322783  0.29070882 0.3535805 ]\n",
      " [0.28494952 0.31605783 0.31698595 0.28486327 0.31110605]\n",
      " [0.         0.         0.         0.12185722 0.        ]\n",
      " [0.32863506 0.35660705 0.35073575 0.30257068 0.33531345]]\n"
     ]
    }
   ],
   "source": [
    "print(tab_TF_normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01661261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38641542, 0.32733512, 0.3322783 , 0.29070882, 0.3535805 ],\n",
       "       [0.28494952, 0.31605783, 0.31698595, 0.28486327, 0.31110605],\n",
       "       [0.        , 0.        , 0.        , 0.12185722, 0.        ],\n",
       "       [0.32863506, 0.35660705, 0.35073575, 0.30257068, 0.33531345]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_TF_normalise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbce02",
   "metadata": {},
   "source": [
    "### Retrait de certaines pages du dictionnaire si TF-IDF trop faible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cf9ccb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil=0.3\n",
    "for id_mot in range(len(dico_mot_page)):\n",
    "    lst = dico_mot_page[str(id_mot)].copy()\n",
    "    for id_page in lst:\n",
    "        if tab_TF_normalise[id_mot][id_page] < seuil: # Ajouter *IDF(id_mot)\n",
    "            dico_mot_page[str(id_mot)].remove(id_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56963930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [0, 1, 2, 4], '1': [1, 2, 4], '2': [], '3': [0, 1, 2, 3, 4]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_mot_page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633cabcd",
   "metadata": {},
   "source": [
    "En fait ce serais plus rapide de construire un dictionnaire mot-page contenant, pour chaque mot, toutes les page existante du corpus. Puis nous supprimerons les page avec un coefficent TF-IDF null."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
